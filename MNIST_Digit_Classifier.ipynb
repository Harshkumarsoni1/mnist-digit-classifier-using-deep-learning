{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb182af3",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Classifier\n",
    "\n",
    "This Jupyter notebook contains a complete end-to-end implementation of a Deep Neural Network (DNN) for classifying handwritten digits using the MNIST dataset with **TensorFlow / Keras**.\n",
    "\n",
    "**What it includes:**\n",
    "- Data loading and preprocessing\n",
    "- Model definition (Flatten → Dense(300) → Dense(100) → Dense(10))\n",
    "- Training with validation\n",
    "- Plots for accuracy & loss\n",
    "- Confusion matrix and sample predictions\n",
    "- Model save / load instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(mnist_X_train_full, mnist_y_train_full), (mnist_X_test, mnist_y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize (0-1) and split validation set\n",
    "X_valid = mnist_X_train_full[:5000] / 255.0\n",
    "X_train = mnist_X_train_full[5000:] / 255.0\n",
    "y_valid = mnist_y_train_full[:5000]\n",
    "y_train = mnist_y_train_full[5000:]\n",
    "X_test = mnist_X_test / 255.0\n",
    "\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Validation shape:', X_valid.shape)\n",
    "print('Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a grid of sample images\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(X_train[i], cmap='binary')\n",
    "    plt.title(str(y_train[i]))\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Sample MNIST images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdac415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(28,28)),\n",
    "    Flatten(),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Save training history to a DataFrame\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "hist = pd.DataFrame(history.history)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "hist[['accuracy','val_accuracy']].plot(title='Accuracy', ax=plt.gca())\n",
    "plt.subplot(1,2,2)\n",
    "hist[['loss','val_loss']].plot(title='Loss', ax=plt.gca())\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, mnist_y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions, confusion matrix & classification report\n",
    "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "cm = confusion_matrix(mnist_y_test, y_test_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(mnist_y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "X_new = X_test[:9]\n",
    "actual = mnist_y_test[:9]\n",
    "y_pred_probs = model.predict(X_new)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i, (img, pred, act) in enumerate(zip(X_new, y_pred, actual)):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(img, cmap='binary')\n",
    "    plt.title(f'Predicted: {pred} | Actual: {act}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Sample predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daca755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('mnist_simple_clf.h5')\n",
    "print('Model saved to mnist_simple_clf.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
